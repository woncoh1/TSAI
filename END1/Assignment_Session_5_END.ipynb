{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_Session_5_END",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woncoh1/END/blob/main/Assignment_Session_5_END.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dee0661-2d09-4c22-88dd-606b0c764e69"
      },
      "source": [
        "!wget -O text.txt https://drive.google.com/u/0/uc?id=1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS&export=download\n",
        "\n",
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-02 10:16:40--  https://drive.google.com/u/0/uc?id=1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.216.100, 173.194.216.139, 173.194.216.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.216.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rks7hmumqvb57brq06co0gvejelkrv99/1606904175000/02008525212197398114/*/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-12-02 10:16:41--  https://doc-14-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rks7hmumqvb57brq06co0gvejelkrv99/1606904175000/02008525212197398114/*/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS\n",
            "Resolving doc-14-3o-docs.googleusercontent.com (doc-14-3o-docs.googleusercontent.com)... 172.217.203.132, 2607:f8b0:400c:c07::84\n",
            "Connecting to doc-14-3o-docs.googleusercontent.com (doc-14-3o-docs.googleusercontent.com)|172.217.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10346 (10K) [text/plain]\n",
            "Saving to: ‘text.txt’\n",
            "\n",
            "text.txt            100%[===================>]  10.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-02 10:16:41 (33.7 MB/s) - ‘text.txt’ saved [10346/10346]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30b9819-9c56-47a5-fd9f-fe11a179fc3b"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 # Size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 # Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size # Size of concatenation(H, X) vector\n",
        "# X_size is the size of (character) vocabulary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return sigmoid(y) * (1 - sigmoid(y))\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x)\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1 - np.square(tanh(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "**Answer: 0.5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvm2xvyIwXXA",
        "outputId": "3683a9c4-6c17-467f-ab1e-25bb25cca48d"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsRJ0e9ryXJB"
      },
      "source": [
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "**Answer: 0.23**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgheq0RtwLTC",
        "outputId": "20ec8883-c483-43f0-b988-cceb4d3aba6b"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2350037122015945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A31ORXx-ydbB"
      },
      "source": [
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "**Answer: 0.23077**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hv0UPK0wRYU",
        "outputId": "88f7d073-de71-4b01-ba7f-7fc8cab44b0a"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2307710272926824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03qBmG4yygaO"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "**Answer: 0.94857**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGA0Ebj9wVza",
        "outputId": "1e55bb04-b142-48cc-fc8c-43a39fb328c5"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9485799654066528"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  `tanh`  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 5\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above.\n",
        "\n",
        "**Answer:**  \n",
        "`size_a` = **`Hidden_Layer_size`**  \n",
        "`size_b` = **`z_size`**  \n",
        "`size_c` = **`X_size`**  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size # why?\n",
        "size_b = z_size # obvious\n",
        "size_c = X_size # given\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        # Features as rows (row: current layer size x col: previous layer size)\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        # For the final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "                self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_t=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_o\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x: 'x_t', h_prev: 'h_t-1', C_prev: 'C_t-1', p = parameters):\n",
        "    \n",
        "    # assure proper input sizes\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))       # h_t-1 and x_t concatenated\n",
        "\n",
        "    f = sigmoid(p.W_f.v @ z + p.b_f.v)  # forget gate layer\n",
        "\n",
        "    i = sigmoid(p.W_i.v @ z + p.b_i.v)  \n",
        "    C_bar = tanh(p.W_C.v @ z + p.b_C.v) # input gate layer\n",
        "\n",
        "    C = f * C_prev + i * C_bar          # C_t (= memory = cell state = context)\n",
        "\n",
        "    o = sigmoid(p.W_o.v @ z + p.b_o.v)  \n",
        "    h = o * tanh(C)                     # h_t (= output)\n",
        "\n",
        "    v = p.W_v.v @ h + p.b_v.v           # logits\n",
        "    y = np.exp(v) / np.sum(np.exp(v))   # softmax (= final layer's prediction)\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 6\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?\n",
        "\n",
        "**Answer: 9**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzkffwko-27J",
        "outputId": "167fdf8e-b765-43ac-fb10-1c905e7de5d7"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 7 \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape) = **(175, 1)**\n",
        "2.   print(np.sum(z)) = **0.0**\n",
        "3.   print(np.sum(f)) = **50.0**\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141bad01-7d89-4cb3-b6df-31e8735ff387"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), \n",
        "                                        np.zeros((Hidden_Layer_size, 1)), \n",
        "                                        np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code.  \n",
        "(Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev: 'for df',\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "  \n",
        "    # assure proper input sizes\n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "      \n",
        "    # calculate error signals (deltas) to update parameters    \n",
        "    dv = np.copy(y) # why (shallow) copy y? \n",
        "    dv[target] -= 1 # why subtract 1 from target?\n",
        "\n",
        "    p.W_v.d += dv @ h.T # update W_v\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = p.W_v.v.T @ dv # W becomes W.T in backward pass  \n",
        "    dh += dh_next\n",
        "\n",
        "    do = dh * tanh(C) # e_l\n",
        "    do *= dsigmoid(p.W_o.v @ z + p.b_o.v) # d_l cf. dsigmoid(o)\n",
        "    p.W_o.d += do @ z.T # update W_o\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next) # why add dC_t'?\n",
        "    dC += dh * o * dtanh(C) # cf. dtanh(tanh(C))\n",
        "\n",
        "    dC_bar = dC * i   \n",
        "    dC_bar *= dtanh(p.W_C.v @ z + p.b_C.v) # cf. dtanh(C_bar) \n",
        "    p.W_C.d += dC_bar @ z.T # update W_C\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar \n",
        "    di *= dsigmoid(p.W_i.v @ z + p.b_i.v) # cf. dsigmoid(i)\n",
        "    p.W_i.d += di @ z.T # update W_i\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df *= dsigmoid(p.W_f.v @ z + p.b_f.v) # cf. dsigmoid(f)\n",
        "    p.W_f.d += df @ z.T # update W_f\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = p.W_f.v.T @ df \\\n",
        "       + p.W_i.v.T @ di \\\n",
        "       + p.W_C.v.T @ dC_bar \\\n",
        "       + p.W_o.v.T @ do\n",
        "    \n",
        "    # output dh_t-1 and hC_t-1 to previous LSTM cell\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC # addition ignored during backpropagation\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Forward pass: Calculate and store the values in forward pass.  \n",
        "Backward pass: Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "Inputs:\n",
        "- `input`, `target` are list of integers, with character indexes.  \n",
        "- `h_prev` is the array of initial h at  t−1  (size H x 1)  \n",
        "- `C_prev` is the array of initial C at  t−1  (size H x 1)\n",
        "\n",
        "Returns loss, final  ht  and  Ct  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global parameters  \n",
        "\n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass \n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dC from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # square gradients\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to an error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "0c818320-f12e-4191-c734-fa5bb2a54d07"
      },
      "source": [
        "iter = 50_000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "  \n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " tran aidina, coughs or reducinf floush Airin ally Desersea fir the everichslyk., stb a ,ous your Deports.\n",
            "\n",
            "You hifly itpulials 60st paside and Heasts are the screening was in Florle worket datien, 27, \n",
            "----\n",
            "iter 49900, loss 4.589648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1VUrcgMSWdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44faa351-684e-4c4f-b856-6ff1c6e9218b"
      },
      "source": [
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.740420062267154"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 8\n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?\n",
        "\n",
        "**Answer:**  \n",
        "Original code: 114.3  \n",
        "Modify backpropagation:\n",
        "1. Modified `do`, `dC_bar`, `di` and `df` with weights only: 98.4  \n",
        "2. Modified `do`, `dC_bar`, `di` and `df` with weights and biases: 76.7  \n",
        "3. Step 2 + modified `dC` from `dtanh(tanh(C))` to `dtanh(C)`: 4.74 (mostly 1 ~ 10)"
      ]
    }
  ]
}